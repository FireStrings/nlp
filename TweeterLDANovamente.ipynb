{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import unidecode\n",
    "import demoji\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from spacy.lang.pt.stop_words import STOP_WORDS\n",
    "import spacy\n",
    "from string import punctuation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk import tokenize\n",
    "import nltk\n",
    "\n",
    "import gensim\n",
    "import sys\n",
    "from gensim.models.phrases import Phraser\n",
    "import gensim.corpora as corpora\n",
    "from pprint import pprint\n",
    "\n",
    "from tqdm import tqdm\n",
    "import tqdm\n",
    "from gensim.models import CoherenceModel\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"pt\")\n",
    "nlp.Defaults.stop_words |= {\"gt\", \"&gt\", \"to\",\"uol\",\"mi\",\"budddhetg\",\"the\", \"ne\", \"vou\", \"ta\", \"via\",\"ex\", \"pq\", \"vc\",\"aa\",\"pra\",\"to\", \"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\", \"n\", \"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\"}\n",
    "palavras_irrelevantes = set(stopwords.words('portuguese') + list(punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanText(tweet):\n",
    "    if \"|\" in tweet:\n",
    "        tweet = tweet.split(\"|\")[1]\n",
    "    \n",
    "    tweet = ' '.join(re.sub(r\"http\\S+\", \"\", tweet).split())\n",
    "    tweet = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|(#[A-Za-z0-9]+)|([0-9])\", \" \", tweet).split())\n",
    "    tweet = ' '.join(re.sub(\"(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "    tweet = ' '.join(re.sub(\"[\\_\\|\\.\\,\\\"\\'\\!\\?\\:\\;\\$\\-\\(\\)\\=]\", \" \", tweet).split())\n",
    "    tweet = tweet.lower()\n",
    "    \n",
    "    le = list(demoji.findall(tweet))\n",
    "    for i in le:\n",
    "        tweet = tweet.replace(i, \"\")\n",
    "    \n",
    "    if tweet.startswith('rt '):\n",
    "        tweet = tweet.replace(\"rt \", \"\")\n",
    "    \n",
    "    lNewTweet = []\n",
    "    for i in tweet.split(\" \"):\n",
    "        if i not in palavras_irrelevantes and i not in STOP_WORDS:\n",
    "            lNewTweet.append(i)\n",
    "    \n",
    "    newTweet = \" \".join(lNewTweet)\n",
    "        \n",
    "    return unidecode.unidecode(newTweet.replace(\" rt \", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>USER</th>\n",
       "      <th>POST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1376863023600599043</td>\n",
       "      <td>g1</td>\n",
       "      <td>Veja a previsão de entrega de vacinas da Fiocr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1376859250056519687</td>\n",
       "      <td>g1</td>\n",
       "      <td>Presidente trocou comandos de Relações Exterio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1376855473828290562</td>\n",
       "      <td>g1</td>\n",
       "      <td>Vítima era obrigada a realizar serviços domést...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1376851704335978500</td>\n",
       "      <td>g1</td>\n",
       "      <td>Os dois defendiam a vacinação nas redes sociai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1376847923758108672</td>\n",
       "      <td>g1</td>\n",
       "      <td>Leia os bastidores no blog do @gcamarotti http...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID USER                                               POST\n",
       "0  1376863023600599043   g1  Veja a previsão de entrega de vacinas da Fiocr...\n",
       "1  1376859250056519687   g1  Presidente trocou comandos de Relações Exterio...\n",
       "2  1376855473828290562   g1  Vítima era obrigada a realizar serviços domést...\n",
       "3  1376851704335978500   g1  Os dois defendiam a vacinação nas redes sociai...\n",
       "4  1376847923758108672   g1  Leia os bastidores no blog do @gcamarotti http..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/dataTweeter.csv\", sep=\";\", encoding='utf8')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>previsao entrega vacinas fiocruz butantan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>presidente trocou comandos relacoes exteriores...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vitima realizar servicos domesticos remuneraca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>defendiam vacinacao redes sociais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>leia bastidores blog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    tweet_text_clean\n",
       "0          previsao entrega vacinas fiocruz butantan\n",
       "1  presidente trocou comandos relacoes exteriores...\n",
       "2  vitima realizar servicos domesticos remuneraca...\n",
       "3                  defendiam vacinacao redes sociais\n",
       "4                               leia bastidores blog"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"tweet_text_clean\"] = data.POST.apply(cleanText)\n",
    "data.drop(columns=[\"ID\", \"USER\", \"POST\"], inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ = [doc.split(\" \") for doc in data[\"tweet_text_clean\"].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = gensim.models.Phrases(token_, min_count=1, threshold=0.1) # higher threshold fewer phrases\n",
    "trigram = gensim.models.Phrases(bigram[token_], threshold=100)\n",
    "\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "l = [trigram_mod[bigram_mod[doc]] for doc in token_]\n",
    "# print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_3 = []\n",
    "token_2 = [[token_3.append(y) for y in x] for x in token_]\n",
    "\n",
    "frequencia = nltk.FreqDist(token_3)\n",
    "freqmc = frequencia.most_common(10000)\n",
    "# freqmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = corpora.Dictionary(l)\n",
    "corpus = [id2word.doc2bow(text) for text in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=9, \n",
    "                                           random_state=100,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=0.31,\n",
    "                                           eta=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "# doc_lda = lda_model[corpus]\n",
    "# print(dir(doc_lda))\n",
    "# print(doc_lda.corpus)\n",
    "# pprint(lda_model.print_topics())\n",
    "# pprint(dir(lda_model))\n",
    "# pprint(lda_model.get_topics())\n",
    "# print(lda_model.show_topic(1))\n",
    "lt = []\n",
    "for i, row in enumerate(lda_model[corpus]):\n",
    "    row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "    lt.append(row[0][0])\n",
    "\n",
    "# print(lt)\n",
    "contents = pd.Series(lt, name=\"topic\")\n",
    "data_new = pd.concat([data, contents], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['situacao brasil alerta manter virus controle requer atencao continua autoridades lideres saude publica',\n",
       " 'edicao participantes capricharam vocabulario conseguiu acompanhar brigas discussoes casa direitinho',\n",
       " 'brasileira desenhos cenarios filme mank concorre oscar confira trabalho',\n",
       " 'tv globo conasems disse ocorreu falha comunicacao pediu retirada campos obrigatorios',\n",
       " 'ultima semana falamos linha frente vacinacao troca ministro saude cerco criticos bolsonaro juros basicos alta esgotamentos utis perdeu algum episodio ouca',\n",
       " 'ultima semana falamos linha frente vacinacao troca ministro saude cerco criticos bolsonaro juros basicos alta esgotamentos utis perdeu algum episodio ouca',\n",
       " 'taos melhor compass lider mercado',\n",
       " 'ministerio saude abre consulta publica inclusao derivado cannabis sus',\n",
       " 'video gravado casa vizinha governador sp entenda',\n",
       " 'assessoria cantor apresenta avancos significativos recuperacao conversado diariamente irmao telefone']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new[data_new[\"topic\"] == 2].sample(10)[\"tweet_text_clean\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def run_markov_chain(transition_matrix, n=10, print_transitions=False):\n",
    "    \"\"\"\n",
    "    Takes the transition matrix and runs through each state of the Markov chain for n time steps. When the chain reaches a steady state, returns the transition probabilities and the time step of the convergence.    \n",
    "    @params:\n",
    "    - transition matrix: transition probabilities\n",
    "    - n: number of time steps to run. default is 10 steps\n",
    "    - print_transitions: tells if we want to print the transition matrix at each time step\n",
    "    \"\"\" \n",
    "    step = transition_matrix    \n",
    "    for time_step in range(1, n):\n",
    "       \n",
    "        if print_transitions:\n",
    "            print('Transition Matrix at step:' + str(time_step))\n",
    "            print(step)\n",
    "            print('-------------------------')      \n",
    "            \n",
    "        next_step = np.matmul(step, transition_matrix).round(2)\n",
    "      \n",
    "        if np.array_equal(step, next_step):\n",
    "            print('Markov chain reached steady-state at time-step = ' + str(time_step))            \n",
    "            if not print_transitions:\n",
    "                print(step)            \n",
    "            return step\n",
    "        else:\n",
    "            step = next_step\n",
    "\n",
    "        \n",
    "        \n",
    "    return step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition Matrix at step:1\n",
      "[[0.1  0.4  0.3  0.2 ]\n",
      " [0.35 0.1  0.25 0.3 ]\n",
      " [0.4  0.3  0.05 0.25]\n",
      " [0.42 0.42 0.08 0.08]]\n",
      "-------------------------\n",
      "Transition Matrix at step:2\n",
      "[[0.35 0.25 0.16 0.23]\n",
      " [0.3  0.35 0.17 0.19]\n",
      " [0.27 0.31 0.22 0.2 ]\n",
      " [0.25 0.27 0.24 0.24]]\n",
      "-------------------------\n",
      "Transition Matrix at step:3\n",
      "[[0.28 0.31 0.19 0.2 ]\n",
      " [0.3  0.29 0.2  0.22]\n",
      " [0.31 0.29 0.19 0.22]\n",
      " [0.32 0.3  0.17 0.21]]\n",
      "-------------------------\n",
      "Transition Matrix at step:4\n",
      "[[0.3  0.28 0.19 0.21]\n",
      " [0.3  0.3  0.19 0.21]\n",
      " [0.3  0.3  0.19 0.21]\n",
      " [0.29 0.3  0.2  0.21]]\n",
      "-------------------------\n",
      "Transition Matrix at step:5\n",
      "[[0.29 0.29 0.19 0.21]\n",
      " [0.3  0.3  0.19 0.21]\n",
      " [0.3  0.3  0.19 0.21]\n",
      " [0.3  0.29 0.19 0.21]]\n",
      "-------------------------\n",
      "Markov chain reached steady-state at time-step = 5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "transition_matrix = np.array([[0.1, 0.4, 0.3, 0.2],\n",
    "                              [0.35, 0.1, 0.25, 0.3],\n",
    "                              [0.4, 0.3, 0.05, 0.25],\n",
    "                              [0.42, 0.42, 0.08, 0.08]])\n",
    "\n",
    "power_transition_matrix = run_markov_chain(transition_matrix, print_transitions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_words = [\"Ola\", \"Bom dia\", \"tudo bem\", \"sou o Leo\"]\n",
    "\n",
    "distinct_words = list(set(corpus_words))\n",
    "word_idx_dict = {word: i for i, word in enumerate(distinct_words)}\n",
    "distinct_words_count = len(list(set(corpus_words)))\n",
    "distinct_words_count # 32663\n",
    "\n",
    "k = 2 # adjustable\n",
    "\n",
    "sets_of_k_words = [ ' '.join(corpus_words[i:i+k]) for i, _ in enumerate(corpus_words[:-k]) ]\n",
    "\n",
    "from scipy.sparse import dok_matrix\n",
    "\n",
    "sets_count = len(list(set(sets_of_k_words)))\n",
    "next_after_k_words_matrix = dok_matrix((sets_count, len(distinct_words)))\n",
    "\n",
    "\n",
    "distinct_sets_of_k_words = list(set(sets_of_k_words))\n",
    "k_words_idx_dict = {word: i for i, word in enumerate(distinct_sets_of_k_words)}\n",
    "\n",
    "for i, word in enumerate(sets_of_k_words[:-k]):\n",
    "   \n",
    "    word_sequence_idx = k_words_idx_dict[word]\n",
    "    \n",
    "    next_word_idx = word_idx_dict[corpus_words[i+k]]\n",
    "    next_after_k_words_matrix[word_sequence_idx, next_word_idx] +=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_next_word_after_sequence(word_sequence, alpha = 0):\n",
    " \n",
    "    next_word_vector = next_after_k_words_matrix[k_words_idx_dict[word_sequence]] + alpha\n",
    "\n",
    "    likelihoods = next_word_vector/next_word_vector.sum()\n",
    "    print(likelihoods)\n",
    "    return weighted_choice(distinct_words, likelihoods.toarray())\n",
    "    \n",
    "def stochastic_chain(seed, chain_length=15, seed_length=4):\n",
    "    current_words = seed.split(' ')\n",
    "    if len(current_words) != seed_length:\n",
    "        raise ValueError(f'wrong number of words, expected {seed_length}')\n",
    "    sentence = seed\n",
    "\n",
    "    for _ in range(chain_length):\n",
    "        sentence+=' '\n",
    "        next_word = sample_next_word_after_sequence(' '.join(current_words))\n",
    "        sentence+=next_word\n",
    "        current_words = current_words[1:]+[next_word]\n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'weighted_choice' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-9baf981b76ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# print(dok_matrix((sets_count, len(distinct_words))))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# print(dok_matrix((50, 50), dtype=np.float32))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mstochastic_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Bom dia tudo bem'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# mtx = dok_matrix((sets_count, len(distinct_words)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-ccc9dc62cdb6>\u001b[0m in \u001b[0;36mstochastic_chain\u001b[0;34m(seed, chain_length, seed_length)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0msentence\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mnext_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_next_word_after_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0msentence\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mnext_word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mcurrent_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_words\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext_word\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-ccc9dc62cdb6>\u001b[0m in \u001b[0;36msample_next_word_after_sequence\u001b[0;34m(word_sequence, alpha)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlikelihoods\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_word_vector\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnext_word_vector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlikelihoods\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mweighted_choice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistinct_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlikelihoods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstochastic_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchain_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'weighted_choice' is not defined"
     ]
    }
   ],
   "source": [
    "# example use    \n",
    "# print()\n",
    "# print(dok_matrix((sets_count, len(distinct_words))))\n",
    "# print(dok_matrix((50, 50), dtype=np.float32))\n",
    "stochastic_chain(seed='Bom dia tudo bem')\n",
    "# mtx = dok_matrix((sets_count, len(distinct_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mtx.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
